{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5939a84-cf6b-490d-b331-9adfc4943475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba6adf38-5306-4792-a80d-4eb8f14720fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a2c6af1-74a6-4d3b-822e-96e4bf3c6909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh Narayanasamy</td>\n",
       "      <td>Fair</td>\n",
       "      <td>Certified Buyer, Chennai</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Quite O. K. , but nowadays  the quality of the...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8514</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8515</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8516</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8517</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8518 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Reviewer Name               Review Title  \\\n",
       "0               Kamal Suresh               Nice product   \n",
       "1          Flipkart Customer     Don't waste your money   \n",
       "2     A. S. Raja Srinivasan   Did not meet expectations   \n",
       "3        Suresh Narayanasamy                       Fair   \n",
       "4                  ASHIK P A                Over priced   \n",
       "...                      ...                        ...   \n",
       "8513                     NaN                        NaN   \n",
       "8514                     NaN                        NaN   \n",
       "8515                     NaN                        NaN   \n",
       "8516                     NaN                        NaN   \n",
       "8517                     NaN                        NaN   \n",
       "\n",
       "                  Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0      Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1      Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2     Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "3        Certified Buyer, Chennai      25.0         1.0       NaN   \n",
       "4                             NaN     147.0        24.0  Apr 2016   \n",
       "...                           ...       ...         ...       ...   \n",
       "8513                          NaN       NaN         NaN       NaN   \n",
       "8514                          NaN       NaN         NaN       NaN   \n",
       "8515                          NaN       NaN         NaN       NaN   \n",
       "8516                          NaN       NaN         NaN       NaN   \n",
       "8517                          NaN       NaN         NaN       NaN   \n",
       "\n",
       "                                            Review text  Ratings  \n",
       "0     Nice product, good quality, but price is now r...        4  \n",
       "1     They didn't supplied Yonex Mavis 350. Outside ...        1  \n",
       "2     Worst product. Damaged shuttlecocks packed in ...        1  \n",
       "3     Quite O. K. , but nowadays  the quality of the...        3  \n",
       "4     Over pricedJust â?¹620 ..from retailer.I didn'...        1  \n",
       "...                                                 ...      ...  \n",
       "8513                                                NaN        5  \n",
       "8514                                                NaN        2  \n",
       "8515                                                NaN        4  \n",
       "8516                                                NaN        1  \n",
       "8517                                                NaN        4  \n",
       "\n",
       "[8518 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6daff04-2600-441c-bc5d-2b2946d5a3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name       10\n",
       "Review Title        10\n",
       "Place of Review     50\n",
       "Up Votes            10\n",
       "Down Votes          10\n",
       "Month              465\n",
       "Review text          8\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfad5a2-50cc-4896-aeaf-a525e1b00cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69e7e960-a9c0-45a0-bff5-a2da3f741f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['Review text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b2aaa00-ed03-4b77-9080-966b8117f7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reviewer Name        2\n",
       "Review Title         2\n",
       "Place of Review     42\n",
       "Up Votes             2\n",
       "Down Votes           2\n",
       "Month              457\n",
       "Review text          0\n",
       "Ratings              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45b63dc9-156f-4755-b0ae-4e08a8e21e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['Ratings']!=3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35626a57-dbb7-4761-897f-d9b806e2ab66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment={\n",
    "    1:0,\n",
    "    2:0,\n",
    "    4:1,\n",
    "    5:1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a7afb0-663d-4aca-9813-20d41a3e8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Sentiment'] = df['Ratings'].map(sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a3b1742-0631-41d5-8a22-82962c697681",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,'Review text'] = df['Review text'].str.replace('READ MORE', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416f41e6-9446-44bb-b9c0-87d269651ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviewer Name</th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Place of Review</th>\n",
       "      <th>Up Votes</th>\n",
       "      <th>Down Votes</th>\n",
       "      <th>Month</th>\n",
       "      <th>Review text</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kamal Suresh</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Certified Buyer, Chirakkal</td>\n",
       "      <td>889.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>Nice product, good quality, but price is now r...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flipkart Customer</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Feb 2021</td>\n",
       "      <td>They didn't supplied Yonex Mavis 350. Outside ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A. S. Raja Srinivasan</td>\n",
       "      <td>Did not meet expectations</td>\n",
       "      <td>Certified Buyer, Dharmapuri</td>\n",
       "      <td>42.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Apr 2021</td>\n",
       "      <td>Worst product. Damaged shuttlecocks packed in ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASHIK P A</td>\n",
       "      <td>Over priced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>Apr 2016</td>\n",
       "      <td>Over pricedJust â?¹620 ..from retailer.I didn'...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baji Sankar</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Certified Buyer, Hyderabad</td>\n",
       "      <td>173.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Oct 2018</td>\n",
       "      <td>Good quality product. Delivered on time.</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>naresh g</td>\n",
       "      <td>For Mavis350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Aug 2016</td>\n",
       "      <td>Received product intact and sealed</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8506</th>\n",
       "      <td>Abani Behera</td>\n",
       "      <td>Don't waste your money</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Sep 2016</td>\n",
       "      <td>up to the mark but same is available in market...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8507</th>\n",
       "      <td>vishnu varma</td>\n",
       "      <td>Really Nice</td>\n",
       "      <td>Certified Buyer, Agartala</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Sep 2016</td>\n",
       "      <td>Nice delivery speed</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8508</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No complaints about the item . Its the best on...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8509</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Not sure why we have charged for this product ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7895 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Reviewer Name               Review Title  \\\n",
       "0               Kamal Suresh               Nice product   \n",
       "1          Flipkart Customer     Don't waste your money   \n",
       "2     A. S. Raja Srinivasan   Did not meet expectations   \n",
       "4                  ASHIK P A                Over priced   \n",
       "5                Baji Sankar      Mind-blowing purchase   \n",
       "...                      ...                        ...   \n",
       "8504                naresh g               For Mavis350   \n",
       "8506            Abani Behera     Don't waste your money   \n",
       "8507            vishnu varma                Really Nice   \n",
       "8508                     NaN                        NaN   \n",
       "8509                     NaN                        NaN   \n",
       "\n",
       "                  Place of Review  Up Votes  Down Votes     Month  \\\n",
       "0      Certified Buyer, Chirakkal     889.0        64.0  Feb 2021   \n",
       "1      Certified Buyer, Hyderabad     109.0         6.0  Feb 2021   \n",
       "2     Certified Buyer, Dharmapuri      42.0         3.0  Apr 2021   \n",
       "4                             NaN     147.0        24.0  Apr 2016   \n",
       "5      Certified Buyer, Hyderabad     173.0        45.0  Oct 2018   \n",
       "...                           ...       ...         ...       ...   \n",
       "8504                          NaN       2.0         1.0  Aug 2016   \n",
       "8506                          NaN       0.0         2.0  Sep 2016   \n",
       "8507    Certified Buyer, Agartala       0.0         1.0  Sep 2016   \n",
       "8508                          NaN       NaN         NaN       NaN   \n",
       "8509                          NaN       NaN         NaN       NaN   \n",
       "\n",
       "                                            Review text  Ratings  Sentiment  \n",
       "0     Nice product, good quality, but price is now r...        4          1  \n",
       "1     They didn't supplied Yonex Mavis 350. Outside ...        1          0  \n",
       "2     Worst product. Damaged shuttlecocks packed in ...        1          0  \n",
       "4     Over pricedJust â?¹620 ..from retailer.I didn'...        1          0  \n",
       "5              Good quality product. Delivered on time.        5          1  \n",
       "...                                                 ...      ...        ...  \n",
       "8504                 Received product intact and sealed        5          1  \n",
       "8506  up to the mark but same is available in market...        4          1  \n",
       "8507                                Nice delivery speed        5          1  \n",
       "8508  No complaints about the item . Its the best on...        5          1  \n",
       "8509  Not sure why we have charged for this product ...        1          0  \n",
       "\n",
       "[7895 rows x 9 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "579529e8-73dd-4d65-bf28-c7786e242be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b42c01-142b-437c-9be5-7b082e67a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text, flag, n=2):\n",
    "    # remove special characters\n",
    "    sentence = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "    # convert sentence into lower case\n",
    "    sentence = sentence.lower()\n",
    "    # tokenize sentence into words\n",
    "    tokens = sentence.split()\n",
    "    \n",
    "    # Remove 'not' from default English stopwords\n",
    "    custom_stopwords = set(stopwords.words(\"english\")) - {'not'}\n",
    "    \n",
    "    # remove stop words\n",
    "    clean_tokens = [token for token in tokens if token not in custom_stopwords]\n",
    "    \n",
    "    # stemming/lemmatization\n",
    "    if flag == 'stem':\n",
    "        clean_tokens = [stemmer.stem(token) for token in clean_tokens]\n",
    "    else:\n",
    "        clean_tokens = [lemmatizer.lemmatize(token) for token in clean_tokens]\n",
    "    \n",
    "    # Generate n-grams\n",
    "    ngrams_list = list(ngrams(clean_tokens, n))\n",
    "    ngrams_text = [' '.join(gram) for gram in ngrams_list]\n",
    "    \n",
    "    return pd.Series(' '.join(ngrams_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5960256c-26ce-456a-a420-13c70267eb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review text'] = df['Review text'].apply(lambda x: preprocess(x, flag='lemmatize', n=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63ecd0a3-4942-40d0-a7be-109d096488f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer()\n",
    "vector.fit_transform(df['Review text']).toarray()\n",
    "text = \"\".join(df['Review text'].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e0db423-5316-49f9-b3c9-6a666ba3a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df['Review text']\n",
    "y=df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db13a42-c431-49df-948a-8660eb169c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce2b35ec-9e00-48f5-aff8-9044c3045761",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29f45cd6-18e4-48ba-9b82-877bcd0ec43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:04:34 INFO mlflow.tracking.fluent: Experiment with name 'sentiment_analysis' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/Acer/Desktop/reviews_data_dump/reviews_badminton/mlruns/722609149144674482', creation_time=1711521274808, experiment_id='722609149144674482', last_update_time=1711521274808, lifecycle_stage='active', name='sentiment_analysis', tags={}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"sentiment_analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d38143f6-c9a1-44bb-9958-a81bc24e984d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"rf_pipe_tfidf = Pipeline([\\n    ('Vectorization', TfidfVectorizer()),\\n    ('classifier', RandomForestClassifier())\\n])\\n\\n# Define the parameter grid for GridSearchCV\\nrf_param_grid_tfidf = {\\n    'Vectorization': [TfidfVectorizer()],\\n    'classifier__n_estimators': [50, 100, 200],\\n    'classifier__max_depth': [None, 10, 20],\\n    'classifier__min_samples_split': [2, 5, 10]\\n}\\n\\n# Initialize GridSearchCV\\nrf_clf_tfidf = GridSearchCV(\\n    estimator=rf_pipe_tfidf, \\n    param_grid=rf_param_grid_tfidf, \\n    scoring='accuracy',\\n    cv=5,\\n    return_train_score=True,\\n    verbose=1\\n)\\n\\n# Enable auto-logging with MLflow\\nmlflow.sklearn.autolog()\\n\\n# Start an MLflow run\\nwith mlflow.start_run() as run:\\n    # Fit the GridSearchCV object\\n    rf_clf_tfidf.fit(X_train, y_train)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the pipeline\n",
    "\"\"\"rf_pipe_tfidf = Pipeline([\n",
    "    ('Vectorization', TfidfVectorizer()),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "rf_param_grid_tfidf = {\n",
    "    'Vectorization': [TfidfVectorizer()],\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "rf_clf_tfidf = GridSearchCV(\n",
    "    estimator=rf_pipe_tfidf, \n",
    "    param_grid=rf_param_grid_tfidf, \n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Enable auto-logging with MLflow\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Fit the GridSearchCV object\n",
    "    rf_clf_tfidf.fit(X_train, y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f468bf6-89b9-4866-9fc4-dddebf58f5b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from sklearn.tree import DecisionTreeClassifier\\n\\n# Define the pipeline\\ndt_pipe_tfidf = Pipeline([\\n    ('Vectorization', TfidfVectorizer()),\\n    ('classifier', DecisionTreeClassifier())\\n])\\n\\n# Define the parameter grid for GridSearchCV\\ndt_param_grid_tfidf = {\\n    'Vectorization': [TfidfVectorizer()],\\n    'classifier__max_depth': [None, 10, 20],\\n    'classifier__min_samples_split': [2, 5, 10]\\n}\\n\\n# Initialize GridSearchCV\\ndt_clf_tfidf = GridSearchCV(\\n    estimator=dt_pipe_tfidf, \\n    param_grid=dt_param_grid_tfidf, \\n    scoring='accuracy',\\n    cv=5,\\n    return_train_score=True,\\n    verbose=1\\n)\\n\\n# Enable auto-logging with MLflow\\nmlflow.sklearn.autolog()\\n\\n# Start an MLflow run\\nwith mlflow.start_run() as run:\\n    # Fit the GridSearchCV object\\n    dt_clf_tfidf.fit(X_train, y_train)\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the pipeline\n",
    "dt_pipe_tfidf = Pipeline([\n",
    "    ('Vectorization', TfidfVectorizer()),\n",
    "    ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "dt_param_grid_tfidf = {\n",
    "    'Vectorization': [TfidfVectorizer()],\n",
    "    'classifier__max_depth': [None, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "dt_clf_tfidf = GridSearchCV(\n",
    "    estimator=dt_pipe_tfidf, \n",
    "    param_grid=dt_param_grid_tfidf, \n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    return_train_score=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Enable auto-logging with MLflow\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run() as run:\n",
    "    # Fit the GridSearchCV object\n",
    "    dt_clf_tfidf.fit(X_train, y_train)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1144066c-76d2-4977-9333-af1bc03409cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'RandomForest': Pipeline([\n",
    "        ('Vectorization', TfidfVectorizer()),\n",
    "        ('classifier', RandomForestClassifier())\n",
    "    ]),\n",
    "    'DecisionTrees': Pipeline([\n",
    "        ('Vectorization', TfidfVectorizer()),\n",
    "        ('classifier', DecisionTreeClassifier())\n",
    "    ]),\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('Vectorization', TfidfVectorizer()),\n",
    "        ('classifier', LogisticRegression())\n",
    "    ]),\n",
    "    'KNeighbors': Pipeline([\n",
    "        ('Vectorization', TfidfVectorizer()),\n",
    "        ('classifier', KNeighborsClassifier())\n",
    "    ]),\n",
    "    'NaiveBayes': Pipeline([\n",
    "        ('Vectorization', TfidfVectorizer()),\n",
    "        ('classifier', MultinomialNB())\n",
    "    ]),\n",
    "    'SVC': Pipeline([\n",
    "        ('Vectorization', TfidfVectorizer()),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "    'XGBoost': Pipeline([\n",
    "        ('Vectorization', TfidfVectorizer()),\n",
    "        ('classifier', XGBClassifier())\n",
    "    ])\n",
    "    \n",
    "}\n",
    "\n",
    "param_grids = {\n",
    "    'RandomForest': {\n",
    "        'Vectorization': [TfidfVectorizer()],\n",
    "        'classifier__n_estimators': [50, 100, 200],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'DecisionTrees': {\n",
    "        'Vectorization': [TfidfVectorizer()],\n",
    "        'classifier__max_depth': [None, 10, 20],\n",
    "        'classifier__min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'LogisticRegression': {\n",
    "        'Vectorization': [TfidfVectorizer()],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'KNeighbors': {\n",
    "        'Vectorization': [TfidfVectorizer()],\n",
    "        'classifier__n_neighbors': [3, 5, 7, 9],\n",
    "        'classifier__p': [1, 2, 3]\n",
    "    },\n",
    "    'NaiveBayes': {\n",
    "        'Vectorization': [TfidfVectorizer()],\n",
    "    },\n",
    "    'SVC': {\n",
    "        'Vectorization': [TfidfVectorizer()],\n",
    "        'classifier__C': [0.1, 1, 10],\n",
    "        'classifier__kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'Vectorization': [TfidfVectorizer()],\n",
    "        'classifier__learning_rate': [0.01, 0.1, 0.3],\n",
    "        'classifier__max_depth': [3, 5, 7],\n",
    "        'classifier__n_estimators': [50, 100, 200]\n",
    "    }\n",
    "     \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "175aa9ec-2ca0-4e6d-9986-f42c0e2f3807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********** RandomForest **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:04:35 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh()\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logged at level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/03/27 12:04:35 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU times: total: 2min 35s\n",
      "Wall time: 2min 47s\n",
      "Train Score:  0.9376786121564603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:07:23 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.9402228976697061\n",
      "\n",
      "********** DecisionTrees **********\n",
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:07:36 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 6.97 s\n",
      "Wall time: 13.1 s\n",
      "Train Score:  0.9344698654350554\n",
      "Test Score:  0.9371833839918946\n",
      "\n",
      "********** LogisticRegression **********\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:07:44 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.23 s\n",
      "Wall time: 7.92 s\n",
      "Train Score:  0.9310914870566769\n",
      "Test Score:  0.9346504559270516\n",
      "\n",
      "********** KNeighbors **********\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "CPU times: total: 2min 24s\n",
      "Wall time: 33.2 s\n",
      "Train Score:  0.9010306192268217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:08:18 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.9103343465045592\n",
      "\n",
      "********** NaiveBayes **********\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:08:24 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 797 ms\n",
      "Wall time: 6.62 s\n",
      "Train Score:  0.8800878093283157\n",
      "Test Score:  0.894630192502533\n",
      "\n",
      "********** SVC **********\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "CPU times: total: 18.7 s\n",
      "Wall time: 24.6 s\n",
      "Train Score:  0.9334564944691527\n",
      "Test Score:  0.939209726443769\n",
      "\n",
      "********** XGBoost **********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/03/27 12:08:49 WARNING mlflow.sklearn: Unrecognized dataset type <class 'pandas.core.series.Series'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "CPU times: total: 5min 15s\n",
      "Wall time: 53.7 s\n",
      "Train Score:  0.9383544303797468\n",
      "Test Score:  0.9422492401215805\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "# Run the Pipeline\n",
    "for algo in pipelines.keys():\n",
    "    print(\"*\"*10, algo, \"*\"*10)\n",
    "    grid_search = GridSearchCV(estimator=pipelines[algo], \n",
    "                               param_grid=param_grids[algo], \n",
    "                               cv=5, \n",
    "                               scoring='accuracy', \n",
    "                               return_train_score=True,\n",
    "                               verbose=1\n",
    "                              )\n",
    "    \n",
    "    mlflow.sklearn.autolog(max_tuning_runs=None)\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        %time grid_search.fit(X_train, y_train)\n",
    "        \n",
    "    print('Train Score: ', grid_search.best_score_)\n",
    "    print('Test Score: ', grid_search.score(X_test, y_test))\n",
    "    \n",
    "    best_models[algo] = grid_search.best_estimator_\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42647d5-d968-4cbe-8a18-9570a28164cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59726b87-80e9-41b5-8b88-04a6d3130db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
